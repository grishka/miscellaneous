**[English](README_en.md)**

![](images/screenshot.jpg)

Это программная реализация декодера аналогового (композитного) видео, также известная как "зачем покупать карту захвата, если можно сделать свою". Оно принимает на вход оцифрованный видеосигнал с АЦП, декодирует его, и отображает его на экране. Также есть возможность записи видео и записи и воспроизведения самих сигналов.

Поддерживается только стандарт SECAM (пока что?).

## Примеры видео

[![](https://img.youtube.com/vi/d2UbD22FDqY/0.jpg)](https://www.youtube.com/watch?v=d2UbD22FDqY)
[![](https://img.youtube.com/vi/5gTD4yl5t5c/0.jpg)](https://www.youtube.com/watch?v=5gTD4yl5t5c)

[Ещё больше примеров в моём телеграм-канале](https://t.me/grishkoblog/83)

## Как оно работает

### Аппаратное обеспечение

Используется плата с чипом АЦП AD9226, купленная на али примерно за 1400 рублей. Она подключена к GPIO Raspberry Pi Zero. Малинка захватывает аналоговый сигнал на частоте 20 МГц с помощью [SMI](https://iosoft.blog/2020/07/16/raspberry-pi-smi/) и передаёт его в реальном времени через USB. Устройство SMI не особенно предназначено для непрерывной работы, но у меня получилось обойти это ограничение, периодически записывая `0xffffffff` в регистр длины передачи и выставляя в 1 бит начала передачи в регистре управления. Данные считываются в два буфера по 512 кб через два DMA control block в цикле.

### Как работает декодирование сигнала

В интернете много информации о том, как *генерировать* видеосигналы, но практически нет о том, как их *декодировать*. Поскольку у меня более-менее получилось написать работающий декодер, переписав всё раз 5 в процессе, кажется разумным это задокументировать :)

Для начала, видеосигнал выглядит вот так ([источник](https://www.batsocks.co.uk/readme/video_timing.htm)):
![](images/Timing_PAL_FrameSignal.gif)

Приложение для macOS получает оцифрованный сигнал теми же кусками по 512 кб. 8-битные семплы преобразуются в float в диапазоне от 0 до 1.

#### Фильтры

Используются 2 типа цифровых фильтров: биквадратичные (IIR) и FIR. Все биквадратичные фильтры рассчитаны с помощью [этого веб-приложения](https://arachnoid.com/BiQuadDesigner/index.html), а FIR-фильтры — с помощью [этого](http://t-filter.engineerjs.com).

Разница между двумя типами фильтров в том, что IIR очень дёшевы в вычислении, но вносят фазовые искажения в сигнал. FIR-фильтры требуют сотен операций умножения и сложения, но имеют фиксированную задержку и не вносят искажений.

Apple предоставляет оба типа (и не только) в Accelerate.framework. Их реализации работают примерно в 1.5 раза быстрее, чем мои наивные.

#### Отделение цветовой поднесущей

*Композитный* видеосигнал так называется потому, что в нём совмещена информация о яркости и цвете. Первый шаг — разделить их, поскольку следующие шаги будут давать лучший результат, если работать только с яркостным компонентом.

Для отделения поднесущей используется FIR-фильтр. Я не помню его точных параметров, но он пропускает частоты в диапазоне примерно 3.8 - 4.6 МГц. На выходе получается цветовая поднесущая (синусоида), отцентрированная относительно нуля. Её можно просто вычесть из сигнала, чтобы получить яркость.

#### Демодуляция цветности

В системе SECAM цвет кодируется с помощью частотной модуляции. Если просто загуглить "frequency demodulation in software without I/Q", найдётся куча статей с математическими формулами и хитрыми алгоритмами вроде PLL (ФАПЧ). Я решил, что нафиг мне это всё не надо, и сделал максимально прямолинейно: просто беру и считаю периоды между переходами синусоиды через ноль. Для достижения большей точности, чем единицы семплов, я использую "линейную интерполяцию наоборот": имея значения функции и координаты по оси X, нахожу координату, в которой между ними будет значение 0. В результате получается число, обратное мгновенному значению частоты сигнала. Эти числа линейно интерполируются между переходами через ноль. Получается на удивление хорошо.

Затем к полученному демодулированному сигналу применяется фильтр для компенсации предыскажений в виде всплесков в местах резких переходов между цветами, внесённых при кодировании:
![](images/deemphasis.png)
(получен методом проб и ошибок, пока картинка не стала выглядеть приемлемо — в интернете абсолютный ноль информации о параметрах этого фильтра)

#### Фильтр низких частот для яркости

Некоторые части следующих шагов используют копию сигнала яркости, пропущенную через этот фильтр, чтобы по максимуму исключить влияние шума:
![](images/lowpass.png)
Эти три сигнала (яркость, цветность, отфильтрованная яркость) далее везде передаются вместе, как такой трёхканальный сигнал.

#### Определение уровней

В реальном мире разные устройства выдают сигналы с разным смещением по напряжению *и* с разным размахом. Нужно определить эти уровни, чтобы правильно выделить синхронизирующие импульсы (см. диаграмму выше). На данный момент нас интересуют только два уровня: уровень "чернее чёрного" для импульсов синхронизации, и сам уровень чёрного. **Крайне важно** определить их правильно, иначе всё будет дёграться и глючить и вообще (угадайте откуда я знаю).

Отфильтрованный сигнал яркости разделяется на 128 равных частей. Для каждой части находится минимальное значение. Затем среднее значение этих частей плюс 0.1 используется как пороговое значение для поиска уровня синхронизации. Среднее значение всех семплов ниже этого уровня принимается за уровень синхроимпульсов.

Для уровня чёрного используется вариация этого же алгоритма, только теперь мы усредняем каждые 40 семплов, пропуская 15 после каждого пересечения порога `уровень синхроимпульсов + 0.08` вверх. Идея в том, чтобы вытащить уровни строчных гасящих импульсов ("back porch" на диаграмме) на каждой строке.

Затем пороговое значение для поиска синхронизирующих импульсов принимается как 25% между уровнями синхронизации и чёрного.

#### Поиск синхроимпульсов

Буфер (+ 1280 семплов следующего буфера) проходится в поисках последовательностей семплов ниже порога, найденного ваше. Периоды длиннее, чем 1.75 мкс (35 семплов) считаются синхроимпульсами и сохраняются для следующих шагов.

#### Разделение на поля (полукадры)

Сигнал разделяется на поля по длинным синхроимпульсам. Какое поле верхнее, а какое — нижнее, определяется путём поиска ближайшего предыдущего строчного синхронизирующего импульса (обычной длины, а не короткого). От количества строк между текущим длинным импульсом синхронизации и найденным коротким берётся дробная часть. Если она близко к 0.5, поле считается нижним. Границы полей сдвигаются таким образом, чтобы нижнее поле включало половину строки, содержащий первый длинный импульс. Таким образом, верхнее поле всегда получается длиной 312 строк, а нижнее — 313.

Если кадровых импульсов синхронизации не было в течение 313 или 312 строк (в зависимости от того, какое поле было последним), соответствующее число семплов всё равно обрабатывается как новое поле.

В следующих шагах обрабатываются поля.

#### Пересчёт уровней для полей

Уровни чёрного и синхронизации пересчитываются для каждого поля примерно так же, как это делалось для буферов, только используются уже найденные положения синхроимпульсов.

#### Разделение на строки

Каждое поле разделяется на строки по синхроимпульсам. Слишком длинные строки (из-за пропущенного импульса) разделяются. Слишком короткие строки объединяются.

Поле, состоящее из массива строк, признака верхнее оно или нижнее, и уровней синхронизации и чёрного, кладётся в очередь.

#### Исправление чересстрочности развёртки

Когда в очереди накапливается 4 поля, проверяются их признаки верхнее/нижнее. Если они у них у всех совпадают, это означает, что либо сигнал совсем кривой, либо нам подсунули прогрессивную развёртку, по типу той, что выдают некоторые игровые приставки. В таком случае поля принудительно делаются чередующимися.

#### Определение уровня белого

Уровень белого по умолчанию устанавливается как `уровень чёрного + (уровень чёрного - уровень синхронизации) * 0.43`. На строках 17 и 330, на которых на большинстве российских каналов передаются испытательные сигналы, содержащие "лесенку" яркости, берётся среднее значение всех семплов, которые превышают уровень белого по умолчанию. Если такие были, для белого используется этот уровень.

В следующих шагах обрабатываются строки.

#### Синхронизация цвета

В системе SECAM цвет кодируется в виде двух компонентов, Db и Dr, передающихся на чередующихся строках. Декодеру нужно знать, на какой строке какой какой из них. Для этого на строках 7-15 и 320-328 передаются такие сигналы:

![](images/color_sync.jpg)

Некоторое количество семплов усредняется в начале и в конце сигнала цветности для каждой из этих строк. Если начало находится в диапазоне от 3.5 до 4.5 МГц, а конец удалён от него не менее, чем на 270 кГц, знак этой разницы используется для для определения красная это строка или синяя.

#### Нормализация цветности

Поскольку нам теперь известно, красная текущая строка или синяя, сигнал цветности, до настоящего момента содержавший числа, обратные частоте, может быть обработан до конца. Это значение частоты преобразуется в настоящую цветность с помощью вычитания и деления.

Затем сигнал пропускается через фильтр низких частот, чтобы убрать шум, который остался в результате демодуляции.

#### Выравнивание строк

Смещения фронтов двух синхронизирующих импульсов вокруг текущей строки находятся с помощью той же "обратной интерполяции", которая использовалась при демодуляции. Яркость и цветность смещаются таким образом, чтобы эти фронты оказались по одинаковому смещению для всех строк.

#### Вывод пикселей

Наконец, из сигналов яркости и цветности, а также второго сигнал цветности, полученного с предыдущей строки, рассчитываются цвета пикселей для вывода в буферы кадра для экрана и записи в видеофайл.

## Если вы хотите запустить это у себя

### Подготовка Raspberry Pi

Подключите плату АЦП:

```
Pi         ADC
GND     -> GND
5V      -> 5V
GPIO 6  -> CLK
GPIO 8  -> D1
GPIO 9  -> D2
GPIO 10 -> D3
GPIO 11 -> D4
GPIO 12 -> D5
GPIO 13 -> D6
GPIO 14 -> D7
GPIO 15 -> D8
```
Используются только 8 бит из 12, потому что на размах сигнала столько хватит, и пропущен младший бит, потому что там всё равно шум.
![](images/rpi_smi_pinout.png)

Запишите образ Debian Bookworm на SD-карту. Добавьте следующее в `boot.txt`, чтобы включить режим USB-устройства:
```
[all]
dtoverlay=dwc2
```
Поместите файлы `adc_stream.service` и `usb_gadget.service` из `rpi` в `/lib/systemd/system`. Поместите исполняемые файлы, `adc_stream` и `usb_init`, и скрипт `usb_gadget` в `/usr/bin` (или соберите их с исходников). Убедитесь, что у них выставлен бит на выполнение. Включите службы:
```
sudo systemctl enable usb_gadget
sudo systemctl enable adc_stream
```
и перезагрузите малинку. Подключите её к маку через порт, который "USB" (не "PWR"). Подключите источник видео к АЦП.

### Приложение для macOS

Установите библиотеку FLAC с помощью Homebrew, она используется для сжатия записанных сигналов:
```
brew install flac
```
Откройте `AVDecoder.xcworkspace` в Xcode, скомпилируйте приложение и запустите его.

Интерфейс достаточно очевиден. Если изображение искажено, подвигайте "смещение сигнала". Записи сохраняются в `~/Movies/AVDecoder`.

## Что будет, если всё-таки подать туда сигнал стандарта PAL?

Вот PAL Валерьич для удовлетворения вашего любопытства:
![](images/PAL.jpg)
